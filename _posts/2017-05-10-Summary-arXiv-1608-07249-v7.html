---
layout: post
title: 논문 한글 요약 - arXiv:1608.07249v7
subtitle: 최신 딥러닝 소프트웨어 도구 벤치마크
---


<section>
  <p>
  이 글은 "Benchmarking State-of-the-Art Deep Learning Software Tools"라는 제목의 논문(<a href="https://arxiv.org/abs/1608.07249v7">arXiv:1608.07249v7</a>) 내용을 아주 간단하게 요약한 것입니다. 논문에서는 최신 딥러닝 소프트웨어 5가지<label for="sn-extensive-use-of-sidenotes" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-extensive-use-of-sidenotes" class="margin-toggle"/><span class="sidenote"><a href="http://caffe.berkeleyvision.org/">Caffe</a>, <a href="https://github.com/microsoft/cntk">CNTK</a>, <a href="http://mxnet.io/">MXNet</a>, <a href="https://www.tensorflow.org/">TensorFlow</a>, <a href="http://torch.ch/">Torch</a></span>의 단위 학습량 당 걸리는 시간을 크게 3가지<label for="sn-extensive-use-of-sidenotes" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-extensive-use-of-sidenotes" class="margin-toggle"/><span class="sidenote">CPU only, single GPU, multi-GPU</span> 상황에서 3가지 신경망<label for="sn-extensive-use-of-sidenotes" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-extensive-use-of-sidenotes" class="margin-toggle"/><span class="sidenote">Fully Connected Network (FCN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN)</span>을 단위 학습량 규모를 바꾸면서 비교합니다. 비교할 때 결과 요약은 다음과 같습니다.
  </p>
</section>


<section>
  <h2>1. CPU only: BEST - TensorFlow</h2>
  <p>
  TensorFlow가 가장 좋았습니다. 비교할 때 16개의 CPU core를 사용했다고 합니다.
  </p>
  
  <h2>2. Single GPU</h2>
  <p>
  <ul>
    <li>Fully Connected Network (FCN): <a href="http://caffe.berkeleyvision.org/">Caffe</a>, <a href="https://github.com/microsoft/cntk">CNTK</a>, <a href="http://torch.ch/">Torch</a> > <a href="http://mxnet.io/">MXNet</a>, <a href="https://www.tensorflow.org/">TensorFlow</a> 라고 합니다.</li>
    <li>Convolutional Neural Network (CNN): network가 큰 경우는 <a href="http://mxnet.io/">MXNet</a>, 작은 경우는 <a href="http://caffe.berkeleyvision.org/">Caffe</a>와 <a href="https://github.com/microsoft/cntk">CNTK</a>도 좋았다고 합니다.</li>
    <li>Recurrent Neural Network (RNN): <a href="https://github.com/microsoft/cntk">CNTK</a>가 다른 4가지에 비해 LSTM RNN<label for="sn-extensive-use-of-sidenotes" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-extensive-use-of-sidenotes" class="margin-toggle"/><span class="sidenote">자세한 내용은 <a href="http://aikorea.org/cs231n/convolutional-networks/">이 글</a>을 참조하시길 바랍니다.</span>으로 5-10배 빠르게 학습한다고 합니다. </li>
  </ul>  
  </p>

  <p>
  <figure>
    <img src="{{ "/images/2017-05-10/arXiv-1608-07249-v7-Figure1.png" | pretend: site.baseurl }}"/>    
  </figure>
  위의 그림은 <a href="https://arxiv.org/abs/1608.07249v7">arXiv:1608.07249v7</a>의 Figure 1입니다.
  </p>

  <h2>3. Multi-GPU</h2>
  <p>
  <ul>
    <li>FCN: <a href="https://github.com/microsoft/cntk">CNTK</a>와 <a href="http://mxnet.io/">MXNet</a>의 경우에, 학습량 규모를 고정하고 GPU 수를 1, 2, 4로 늘릴 때 처리 시간이 가장 잘 줄어든다고 합니다. GPU 개수를 늘릴 때 처리 시간이 잘 줄어들수록 여러개의 GPU를 더 효율적으로 사용한다는 의미입니다.</li>
    <li>CNN(AlexNet): <a href="http://mxnet.io/">MXNet</a>과 <a href="http://torch.ch/">Torch</a>의 경우에, GPU 수를 위와 같이 늘리면 처리 시간이 가장 잘 줄어든다고 합니다. <a href="https://github.com/microsoft/cntk">CNTK</a>는 <a href="http://mxnet.io/">MXNet</a>과 <a href="http://torch.ch/">Torch</a>에 비해 줄어드는 정도가 살짝 작지만 <a href="http://caffe.berkeleyvision.org/">Caffe</a>나 <a href="https://www.tensorflow.org/">TensorFlow</a>보다는 훨씬 더 잘 줄어든다고 합니다.</li>
    <li>CNN(ResNet): GPU를 1개만 사용했을 때는 <a href="http://mxnet.io/">MXNet</a>이 가장 좋았지만, 여러개를 사용했을 때는 <a href="http://torch.ch/">Torch</a>가 더 효율적인 것으로 나타났다고 합니다.</li>
  </ul>
  </p>
</section>


<section>
  <h2>기타 사항</h2>
  <p>
  <ul>
    <li>NVIDIA® GTX 980, NVIDIA® GTX 1080, NVIDIA® Tesla K80 GK210 중에서 NVIDIA® GTX 1080이 가장 좋았다고 합니다.</li>
    <li>GPU를 사용할 때는 cuDNN을 꼭 설치하여 소프트웨어가 사용할 수 있도록 하기를 권장하고 있습니다.</li>    
    <li>Convolution을 직접 계산하기보다는 FFT 하기를 권장하고 있습니다.</li>        
  </ul>
  </p>
</section>



<script type="text/javascript" src="{{ "/js/footnotes.js" | prepend: site.baseurl }}"></script>
<script type="text/javascript" src="{{ "/js/highlight.pack.js" | prepend: site.baseurl }}"></script>
<script>hljs.initHighlightingOnLoad();</script>
<!-- http://tsi.github.io/inlineDisqussions/ -->

<script>
disqus_shortname = 'danielykim';

jQuery(document).ready(function() {
  jQuery("p").inlineDisqussions();
});

jQuery("p").inlineDisqussions({
  identifier: 'disqussion',
  displayCount: true,
  highlighted: true,
  position: 'right',
  background: '#FFFFF9',
  maxWidth: 200
});
</script>
